"I would use at least two hidden layers, ReLU activation functions between adjacent layers, and employ backward error propagation for training.","Propose an argument for why a Deep Neural Network (DNN) containing at least two hidden layers is necessary for solving complex classification problems, contrasting it with a single-layer perceptron's limitations.",Create a set of step-by-step instructions for modifying the Keras XOR code sample (Listing 4.1) to train a model specifically for the logical AND function.,How would you design a Keras-based Multi-layer Perceptron (MLP) architecture specifically engineered to efficiently learn a non-linearly separable function like NAND?,Devise a visualization technique to show how the inclusion of a nonlinear activation function allows a Multilayer Perceptron (MLP) to separate data that is not linearly separable in the Euclidean plane (like the XOR function).,How would you design a Keras-based Multi-layer Perceptron (MLP) architecture specifically engineered to efficiently learn a non-linearly separable function like NAND?
"Use Average Pooling instead, which averages values in a window instead of selecting the maximum, or implement a more complex architecture like capsule networks, a proposed replacement for max pooling.",Design a custom 5x5 filter (kernel) intended to detect vertical line features in an image during the Convolutional Layer (Conv2D) operation.,Devise an alternative technique to Max Pooling in a Convolutional Neural Network (CNN) that focuses on preserving localized feature intensity rather than maximal value selection.,How would you integrate Average Pooling and Max Pooling strategically within a deep CNN architecture to maximise spatial information retention while still reducing feature map size?.,"Create a rule set defining when to use different pooling layer algorithms (maximum value, average, or square root of the sum of squares) based on the input data characteristics.",Devise an alternative technique to Max Pooling in a Convolutional Neural Network (CNN) that focuses on preserving localized feature intensity rather than maximal value selection.
"I would use parallelized metaheuristics, which are considered ""any-time methods"" capable of proposing a good, rapid solution when dealing with regularly updated data.",How would you propose a strategy using metaheuristics to solve a data mining task related to the Big Data challenge of Data Velocity?,Propose how the capability of metaheuristics to consider various types of data simultaneously addresses the challenge of Data Variety in Big Data analytics.,"Design a conceptual system architecture that integrates parallel machine learning and data mining algorithms (ML-DM) with an underlying Big Data platform to manage massive, high-velocity data streams.","Formulate an objective function for a metaheuristic search algorithm designed to prioritize rapid convergence when analyzing high-velocity stream data, even at the expense of absolute global optimality.",How would you propose a strategy using metaheuristics to solve a data mining task related to the Big Data challenge of Data Velocity?
"I would design a framework that must evaluate the confidence or trust in the data by analyzing its provenance, reliability, context, and meaningfulness for the intended analysis.","Create a policy brief justifying why a company focused on Big Data analysis must evolve its perspective from collecting ""Big Data"" to generating ""Smart Data"".","Devise a strategy for transforming internal company data deemed to have low ""Veracity"" (uncertainty) into useful information through specialised data cleaning and modelling techniques.","How would you design a small framework to help decision-makers assess the ""Veracity"" dimension of a new social media dataset?","How would you establish a protocol to manage the ""Volatility"" of IoT sensor data (describing how long data is stored) to ensure its historical context is retained for longitudinal analysis?.","How would you design a small framework to help decision-makers assess the ""Veracity"" dimension of a new social media dataset?"
I would create a new function that handles positive inputs like ReLU (ReLU(x) = x if x â‰¥ 0) which avoids the vanishing gradient problem while also ensuring output normalization like Tanh by scaling negative inputs toward zero.,"Create a rule set defining when to switch activation functions (e.g., from ReLU in hidden layers to Softmax in the output layer) within a neural network performing a multi-class classification task.","Develop an argument for using the Tanh function over the Sigmoid function in LSTMs, given that both are continuous and differentiable, focusing on gradient stability.","Design a detailed process for adjusting the weight initialization (a hyperparameter) in a neural network to maximise the effectiveness of the ReLU activation function, particularly around the origin.","How would you create a new activation function definition optimized for mitigating the vanishing gradient problem, combining ReLU and Tanh properties?","How would you create a new activation function definition optimized for mitigating the vanishing gradient problem, combining ReLU and Tanh properties?"
"First combine a CNN to process each input image in the video sequence, then use an LSTM to analyze the sequential temporal data and make positional predictions.",Propose how deep reinforcement learning (combining reinforcement learning with deep architectures) could be used to optimize autonomous driving decisions based on real-time video input processed by a CNN/LSTM sequence.,Develop a conceptual architecture using CNNs and LSTMs for a sophisticated video analysis task: predicting the future trajectory of objects.,Design an LSTM-based model structure for Natural Language Processing (NLP) that leverages the Forget Gate mechanism to capture long-term dependencies while efficiently mitigating the vanishing gradient problem.,"Devise a monitoring strategy that uses RNNs to analyze audio signals converted to digital parameters, allowing for the reliable distinction between a harmless sound (e.g., vehicle backfire) and a critical event (e.g., a gunshot).",Develop a conceptual architecture using CNNs and LSTMs for a sophisticated video analysis task: predicting the future trajectory of objects.
"The selection criteria should prioritise technologies like graph databases, which are specifically based on node relationships and designed to deal with highly interconnected data.","Propose a comparison framework for evaluating key-value pair databases versus document databases, based on how well each handles the variety of structured and semi-structured data sources often encountered in Big Data.",Devise a criteria set for selecting an appropriate non-relational database technology (NoSQL) to manage highly interconnected social network data.,How would you design a robust data transportation strategy to ensure the security of data (including its confidentiality and integrity) when moving massive volumes from distributed sources to central data centres?.,Create a justification brief explaining why traditional relational database management systems are less adapted than NoSQL technologies for Big Data contexts involving high scalability and variety (including unstructured data).,Devise a criteria set for selecting an appropriate non-relational database technology (NoSQL) to manage highly interconnected social network data.
I would create a workflow that involves specific preprocessing steps to convert the complex raw data (natural language text) into a structured sequence of numbers that can be interpreted by a machine learning algorithm.,How would you create a preparatory process workflow to transform raw text data (like customer feedback emails) into a structured format suitable for machine learning algorithms?,"Devise a comprehensive classification system to sort various raw data sources (e.g., HTML code, video, banking transactions, DNA sequences) into the categories of structured, semi-structured, and unstructured data.","Design a system that leverages the Internet of Things (IoT) sensors to capture climate information, and outlines how this high-volume data stream is indexed and stored for later analysis.","Create a business plan for a new company whose core business model (mechanism 3 or 5) is built entirely from scratch based on collecting and analyzing highly diverse location data (GPS, Wi-Fi connections).",How would you create a preparatory process workflow to transform raw text data (like customer feedback emails) into a structured format suitable for machine learning algorithms?
"Either implement Batch normalization to stabilize the network and normalize output, or use L2 regularization (penalizing squared weight values) to make weights smaller during training.","How would you create a system alert to flag the occurrence of the ""vanishing gradient problem"" during back propagation, and what automated fix would you propose using a hyperparameter adjustment?.","Create a methodology for balancing the complexity of an ANN model (e.g., number of hidden layers and neurons) against the goal of ensuring the model generalizes well and avoids overfitting.",Propose a revised training process methodology designed to prevent overfitting in a deep learning model before manually adjusting the Dropout hyperparameter.,Design an experiment to determine the optimal learning rate (a critical hyperparameter) for a neural network by monitoring how different step magnitudes affect the model's approach to the optimal point.,Propose a revised training process methodology designed to prevent overfitting in a deep learning model before manually adjusting the Dropout hyperparameter.
"The methodology involves transforming extracted patterns into knowledge, evaluating if the knowledge has real value (is it new?), and confirming whether it answers the identified KDD goals, reiterating the process if needed.",Design a visualisation tool interface intended to help decision-makers easily interpret and verify the complex results produced by a Big Data mining approach.,"Create a checklist for evaluating whether extracted patterns from a data mining task (Data Mining step) are truly ""novel,"" ""useful,"" and ""understandable"" to decision-makers.","Devise a sequential process for the Selection/Cleaning stage of the KDD pipeline when initially handling massive, highly redundant sensor network data, ensuring useful information is not discarded.",Outline a methodology for the Interpretation/Evaluation stage of the Knowledge Discovery in Databases (KDD) process when dealing with extracted patterns from a Big Data classification model.,Outline a methodology for the Interpretation/Evaluation stage of the Knowledge Discovery in Databases (KDD) process when dealing with extracted patterns from a Big Data classification model.